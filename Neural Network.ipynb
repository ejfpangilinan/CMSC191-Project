{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6223115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "import random\n",
    "from decimal import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "from sklearn.metrics import f1_score,confusion_matrix,roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb85336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function and partial derivatives\n",
    "\n",
    "#define sigmoid activation function\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1.0 + np.exp(-x))\n",
    "\n",
    "# neuron derivatives\n",
    "def n_derivatives(z):\n",
    "\treturn z * (1.0 - z)\n",
    "\n",
    "\n",
    "#evaluation functions\n",
    "def evaluation(y_test,y_pred):\n",
    "\n",
    "\tacc = accuracy_score(y_test,y_pred)\n",
    "\trcl = recall_score(y_test,y_pred)\n",
    "\tf1 = f1_score(y_test,y_pred)\n",
    "\tauc_score = roc_auc_score(y_test,y_pred)\n",
    "\tprec_score = precision_score(y_test,y_pred)\n",
    "\n",
    "\tmetric_dict={'accuracy': round(acc,3),\n",
    "\t           'recall': round(rcl,3),\n",
    "\t           'F1 score': round(f1,3),\n",
    "\t           'auc score': round(auc_score,3),\n",
    "\t           'precision': round(prec_score,3) \n",
    "\t          }\n",
    "\n",
    "\treturn print(metric_dict)\n",
    "\n",
    "#normalize the prediction \n",
    "def normalize(pred):\n",
    "\tret = np.array((pred))\n",
    "\n",
    "\tfor i in range(len(pred)):\n",
    "\t\tif pred[i]>=0.5: #tp\n",
    "\t\t\tret[i]=1\n",
    "\t\telse:\n",
    "\t\t\tret[i]=0\n",
    "\n",
    "\treturn ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd43ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Class\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "\t\"\"\"Make a 3-layer network (5-4-1)\"\"\"\n",
    "\tdef __init__(self, X, Y):\n",
    "\t\t#initialized important variables\n",
    "\n",
    "\t\tself.inputs = X\n",
    "\n",
    "\t\tself.hidden_weights = np.random.uniform(low=-0.1, high=0.1, size=(self.inputs.shape[1],4))#weights of hidden layer\n",
    "\t\tself.hidden_bias = np.random.uniform(low=-0.1, high=0.1, size=(4,)) #bias of hidden layer\n",
    "\n",
    "\t\tself.output_weights = np.random.uniform(low=-0.1, high=0.1, size=(4,1)) #weights of output layer\n",
    "\t\tself.ouput_bias = np.random.uniform(low=-0.1, high=0.1, size=(1,))  #bias of the output layer\n",
    "\n",
    "\t\t#------------------------------------------------------------------------------------------------------------#\n",
    "\t\t# self.hidden_weights = np.full((self.inputs.shape[1],3), 0.5, dtype=float) #weights of hidden layer\n",
    "\t\t# self.hidden_bias = np.full((3,), 0.5, dtype=float) #bias of hidden layer\n",
    "\n",
    "\t\t# self.output_weights = np.full((3,1), 0.5, dtype=float) #weights of output layer\n",
    "\t\t# self.ouput_bias = np.full((1,), 0.5, dtype=float) #bias of the output layer\n",
    "\t\t#------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\t\tself.a_out = Y.reshape(len(Y),1)#actual outputs\n",
    "\t\tself.p_outputs = np.zeros(Y.shape) #holds predicted outputs\n",
    "\n",
    "\t\tprint(\"Hidden Nodes Weights: \\n\",self.hidden_weights, \"\\nHidden Nodes Biases: \\n\",self.hidden_bias)\n",
    "        \n",
    "\t\tprint(\"Output Nodes Weights: \\n\",self.output_weights, \"\\nOutput Nodes Biases: \\n\",self.ouput_bias)\n",
    "\n",
    "\tdef predict(self,X):\n",
    "\t\t#predict using a different input\n",
    "\t\tself.inputs = X\n",
    "\t\treturn normalize(self.forward_pass())\n",
    "\n",
    "\tdef forward_pass(self):\n",
    "\t\tself.hidden_nodes = sigmoid(np.add(np.dot(self.inputs, self.hidden_weights),self.hidden_bias)) #contains hidden node inputs\n",
    "\t\toutputs = sigmoid(np.add(np.dot(self.hidden_nodes, self.output_weights),self.ouput_bias)) #contain output prediction\n",
    "\t\treturn outputs\n",
    "\n",
    "\tdef back_propagration(self,l_rate):\n",
    "\t\t#output error and delta\n",
    "\t\tself.output_error = self.a_out - self.p_outputs\n",
    "\t\tself.output_delta = self.output_error * n_derivatives(self.p_outputs)\n",
    "\n",
    "\t\t#hidden error and delta\n",
    "\t\tself.hidden_error = np.dot(self.output_delta,self.output_weights.T)\n",
    "\t\tself.hidden_delta = self.hidden_error*n_derivatives(self.hidden_nodes)\n",
    "\n",
    "\t\t#update weights\n",
    "\t\tself.output_weights += np.dot(self.hidden_nodes.T,self.output_delta) * l_rate\n",
    "\t\tself.hidden_weights += np.dot(self.inputs.T,self.hidden_delta) * l_rate\n",
    "\n",
    "\t\t# #update biases\n",
    "\t\tself.hidden_bias  += np.sum(self.hidden_delta,axis=0) * l_rate\n",
    "\t\tself.ouput_bias += np.sum(self.output_delta,axis=0)  *l_rate\n",
    "\t\treturn\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tself.p_outputs = self.forward_pass()\n",
    "\t\tself.back_propagration(0.00001) #use learning rate\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef217a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8143 entries, 1 to 8143\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           8143 non-null   object \n",
      " 1   Temperature    8143 non-null   float64\n",
      " 2   Humidity       8143 non-null   float64\n",
      " 3   Light          8143 non-null   float64\n",
      " 4   CO2            8143 non-null   float64\n",
      " 5   HumidityRatio  8143 non-null   float64\n",
      " 6   Occupancy      8143 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 508.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIndependent Variables:\\n-Temperature, Humidity, Light, CO2, HumidityRatio\\nDependent Variable: \\n-Occupancy\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the Datasets\n",
    "\n",
    "#CLEAN THE DATASET\n",
    "# load data\n",
    "test1 = read_csv('datatest.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "train = read_csv('datatraining.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "test2 = read_csv('datatest2.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "values = train.values\n",
    "#separate inputs and output values\n",
    "INPUT, OUTPUT = values[:, 1:-1], values[:, -1]\n",
    "X, Y = np.array((INPUT),dtype=float), np.array((OUTPUT),dtype=float)\n",
    "\n",
    "values1 = test1.values\n",
    "#separate inputs and output values\n",
    "INPUT1, OUTPUT1 = values1[:, 1:-1], values1[:, -1]\n",
    "X1, Y1 = np.array((INPUT1),dtype=float), np.array((OUTPUT1),dtype=float)\n",
    "\n",
    "values2 = test2.values\n",
    "#separate inputs and output values\n",
    "INPUT2, OUTPUT2 = values2[:, 1:-1], values2[:, -1]\n",
    "X2, Y2 = np.array((INPUT2),dtype=float), np.array((OUTPUT2),dtype=float)\n",
    "\n",
    "print(train.info())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Independent Variables:\n",
    "-Temperature, Humidity, Light, CO2, HumidityRatio\n",
    "Dependent Variable: \n",
    "-Occupancy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef48a3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Nodes Weights: \n",
      " [[-0.00606723 -0.0909193  -0.07372386  0.09959427]\n",
      " [ 0.05901565  0.03703342 -0.07642853  0.01572788]\n",
      " [ 0.09361881 -0.02215084 -0.09135864  0.08583708]\n",
      " [ 0.00293935  0.0224781  -0.07544568 -0.02731063]\n",
      " [-0.0432646  -0.05462081  0.04466519 -0.07196674]] \n",
      "Hidden Nodes Biases: \n",
      " [-0.06196543  0.06961126 -0.08614653  0.01436121]\n",
      "Output Nodes Weights: \n",
      " [[ 0.04734569]\n",
      " [ 0.06602199]\n",
      " [-0.03927068]\n",
      " [ 0.08025851]] \n",
      "Output Nodes Biases: \n",
      " [0.02000303]\n",
      "Epoch 0 Loss: 0.2123296082524868\n",
      "Epoch 100 Loss: 0.16059377750194095\n",
      "Epoch 200 Loss: 0.13100918819636348\n",
      "Epoch 300 Loss: 0.11307521671620871\n",
      "Epoch 400 Loss: 0.10249366489903393\n",
      "Epoch 500 Loss: 0.09204661413405116\n",
      "Epoch 600 Loss: 0.08340519123104284\n",
      "Epoch 700 Loss: 0.07808165415531416\n",
      "Epoch 800 Loss: 0.0754877168141456\n",
      "Epoch 900 Loss: 0.07164916031977182\n",
      "Epoch 1000 Loss: 0.0670813306376413\n",
      "Epoch 1100 Loss: 0.0671409787821466\n",
      "Epoch 1200 Loss: 0.06480587586101119\n",
      "Epoch 1300 Loss: 0.062349668313736756\n",
      "Epoch 1400 Loss: 0.06077039819412457\n"
     ]
    }
   ],
   "source": [
    "#Create the Neural Network and Train using the training dataset\n",
    "\n",
    "#epoch = 1500 with learning rate of 0.00001\n",
    "\n",
    "NN = NeuralNetwork(X, Y)\n",
    "\n",
    "for epoch in range(1500):\t\n",
    "    if epoch % 100==0: \n",
    "        print (\"Epoch \" + str(epoch) + \" Loss: \" + str(np.mean(np.square(NN.a_out- NN.p_outputs)))) # mean squared error for loss\n",
    "    NN.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d6dc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION TRAIN\n",
      "{'accuracy': 0.934, 'recall': 0.995, 'F1 score': 0.865, 'auc score': 0.957, 'precision': 0.765}\n",
      "EVALUATION TEST1\n",
      "{'accuracy': 0.979, 'recall': 1.0, 'F1 score': 0.972, 'auc score': 0.983, 'precision': 0.946}\n",
      "EVALUATION TEST2\n",
      "{'accuracy': 0.946, 'recall': 0.999, 'F1 score': 0.885, 'auc score': 0.965, 'precision': 0.795}\n"
     ]
    }
   ],
   "source": [
    "#evaluate the Neural Network\n",
    "print(\"EVALUATION TRAIN\")\n",
    "evaluation(NN.a_out,normalize(NN.p_outputs))\n",
    "print(\"EVALUATION TEST1\")\n",
    "evaluation(Y1,NN.predict(X1))\n",
    "print(\"EVALUATION TEST2\")\n",
    "evaluation(Y2,NN.predict(X2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804b8348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] [1]\n"
     ]
    }
   ],
   "source": [
    "#sample prediction\n",
    "\n",
    "#23.7,26.272,585.2,749.2,0.00476416302416414,1\n",
    "#x = [\"Temperature\",\"Humidity\",\"Light\",\"CO2\",\"HumidityRatio\"]\n",
    "#y = [\"Actual Occupancy\"]\n",
    "\n",
    "x= [23.7,26.272,585.2,749.2,0.00476416302416414]\n",
    "y= [1]\n",
    "\n",
    "\n",
    "print(normalize(NN.predict(x)),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832813e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
