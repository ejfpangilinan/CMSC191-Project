{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5eabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "import random\n",
    "from decimal import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "from sklearn.metrics import f1_score,confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39af0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20560 entries, 140 to 9752\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           20560 non-null  object \n",
      " 1   Temperature    20560 non-null  float64\n",
      " 2   Humidity       20560 non-null  float64\n",
      " 3   Light          20560 non-null  float64\n",
      " 4   CO2            20560 non-null  float64\n",
      " 5   HumidityRatio  20560 non-null  float64\n",
      " 6   Occupancy      20560 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "number of training set \n",
      " input:  14392 \n",
      " output:  14392\n",
      "number of test set \n",
      " input:  6168 \n",
      " output:  6168\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Datasets\n",
    "\n",
    "#CLEAN THE DATASET\n",
    "# load data\n",
    "test1 = read_csv('datatest.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "train = read_csv('datatraining.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "test2 = read_csv('datatest2.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "# vertically stack and maintain temporal order\n",
    "data = concat([test1, train, test2])\n",
    "\n",
    "values = data.values\n",
    "#separate inputs and output values\n",
    "INPUT, OUTPUT = values[:, 1:-1], values[:, -1]\n",
    "X, Y = np.array((INPUT),dtype=float), np.array((OUTPUT),dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "# split the dataset\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, shuffle=False, random_state=1)\n",
    "\n",
    "#print dataset information\n",
    "print(data.info())\n",
    "print(\"number of training set \\n input: \", len(trainX),\"\\n output: \",len(trainY))\n",
    "print(\"number of test set \\n input: \", len(testX),\"\\n output: \",len(testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2579426b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 10739]\n",
      " [    1  3653]]\n"
     ]
    }
   ],
   "source": [
    "#get the frequency count of occupied(1) vs not occuppied(0) in the dataset\n",
    "unique, counts = np.unique(trainY, return_counts=True)\n",
    "freq_array = np.asarray((unique, counts),dtype=int).T\n",
    "print (freq_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd694338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7086 7086\n"
     ]
    }
   ],
   "source": [
    "#upsample the training Data for occuppied(1):\n",
    "up_x = []\n",
    "up_y = []\n",
    "\n",
    "r = (freq_array[0][1]-freq_array[1][1])\n",
    "add = 0\n",
    "cnt=0\n",
    "\n",
    "while add!=r:\n",
    "    if trainY[cnt]==1:\n",
    "        up_x.append(trainX[cnt])\n",
    "        up_y.append(trainY[cnt])\n",
    "        add+=1\n",
    "        \n",
    "    cnt+=1\n",
    "    if cnt>=len(trainY) and add<r:\n",
    "        cnt=0\n",
    "    \n",
    "        \n",
    "up_x = np.array((up_x),dtype=float)\n",
    "up_y = np.array((up_y),dtype=float)\n",
    "\n",
    "print(len(up_x),len(up_y))\n",
    "\n",
    "trainX = np.append(trainX,up_x)\n",
    "trainY = np.append(trainY,up_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52241540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 10739]\n",
      " [    1 10739]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get the frequency count of occupied(1) vs not occuppied(0) in the dataset after upsampling\n",
    "unique, counts = np.unique(trainY, return_counts=True)\n",
    "freq_array = np.asarray((unique, counts),dtype=int).T\n",
    "\n",
    "print (freq_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b46c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sigmoid activation function\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1.0 + np.exp(-x))\n",
    "\n",
    "# neuron derivatives\n",
    "def n_derivatives(z):\n",
    "\treturn z * (1.0 - z)\n",
    "\n",
    "\n",
    "def confusion_matrix(pred, out):\n",
    "\tconf = {\"tp\": 0,\n",
    "\t\t\t\"tn\": 0,\n",
    "\t\t\t\"fp\": 0,\n",
    "\t\t\t\"fn\":0}\n",
    "\n",
    "\tfor i in range(len(pred)):\n",
    "\t\tif pred[i]>=0.5 and out[i] == 1.0: #tp\n",
    "\t\t\tconf[\"tp\"]+=1\n",
    "\t\telif pred[i]<0.5 and out[i] == 0.0: #tn\n",
    "\t\t\tconf[\"tn\"]+=1\n",
    "\t\telif pred[i]>=0.5 and out[i] == 0.0: #fp\n",
    "\t\t\tconf[\"fp\"]+=1\n",
    "\t\telif pred[i]<0.5 and out[i] == 1.0: #fn\n",
    "\t\t\tconf[\"fn\"]+=1\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\treturn conf\n",
    "\n",
    "def normalize(pred):\n",
    "\tret = np.array((pred))\n",
    "\n",
    "\tfor i in range(len(pred)):\n",
    "\t\tif pred[i]>=0.5: #tp\n",
    "\t\t\tret[i]=1\n",
    "\t\telse:\n",
    "\t\t\tret[i]=0\n",
    "\n",
    "\treturn ret\n",
    "\n",
    "def conf_accuracy(pred,out):\n",
    "\tconfu = confusion_matrix(pred,out)\n",
    "\n",
    "\treturn (confu[\"tp\"]+confu[\"tn\"]) / len(pred)\n",
    "\n",
    "\n",
    "def evaluation(y_test,y_pred):\n",
    "\n",
    "\tacc = accuracy_score(y_test,y_pred)\n",
    "\trcl = recall_score(y_test,y_pred)\n",
    "\tf1 = f1_score(y_test,y_pred)\n",
    "\tauc_score = roc_auc_score(y_test,y_pred)\n",
    "\tprec_score = precision_score(y_test,y_pred)\n",
    "\n",
    "\tmetric_dict={'accuracy': round(acc,3),\n",
    "\t           'recall': round(rcl,3),\n",
    "\t           'F1 score': round(f1,3),\n",
    "\t           'auc score': round(auc_score,3),\n",
    "\t           'precision': round(prec_score,3) \n",
    "\t          }\n",
    "\n",
    "\treturn print(metric_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711acb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "\t\"\"\"Make a 3-layer network (5-4-1)\"\"\"\n",
    "\tdef __init__(self, X, Y, mode):\n",
    "\t\t#initialized important variables\n",
    "\n",
    "\t\tself.inputs = X\n",
    "\n",
    "\t\tif mode==0:\n",
    "\n",
    "\t\t\tself.hidden_weights = np.random.uniform(low=-1.0, high=1.0, size=(self.inputs.shape[1],4))#weights of hidden layer\n",
    "\t\t\tself.hidden_bias = np.random.uniform(low=-1.0, high=1.0, size=(4,)) #bias of hidden layer\n",
    "\n",
    "\t\t\tself.output_weights = np.random.uniform(low=-1.0, high=1.0, size=(4,1)) #weights of output layer\n",
    "\t\t\tself.ouput_bias = np.random.uniform(low=-1.0, high=1.0, size=(1,))  #bias of the output layer\n",
    "\n",
    "\t\t\t#------------------------------------------------------------------------------------------------------------#\n",
    "\t\t\t# self.hidden_weights = np.full((self.inputs.shape[1],3), 0.5, dtype=float) #weights of hidden layer\n",
    "\t\t\t# self.hidden_bias = np.full((3,), 0.5, dtype=float) #bias of hidden layer\n",
    "\n",
    "\t\t\t# self.output_weights = np.full((3,1), 0.5, dtype=float) #weights of output layer\n",
    "\t\t\t# self.ouput_bias = np.full((1,), 0.5, dtype=float) #bias of the output layer\n",
    "\t\t\t#------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\t\telif mode == 1:\n",
    "\n",
    "\t\t\t# inp =  str(input(\"Enter model file name:\"))\n",
    "\t\t\t# model_file = np.load(str(inp+'.npy'),allow_pickle='TRUE').item()\n",
    "\t\t\tmodel_file = np.load('model.npy',allow_pickle='TRUE').item()\n",
    "\t\t\tself.load_model(model_file)\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tprint(\"INVALID MODE\")\n",
    "\t\t\texit()\n",
    "\t\t\n",
    "\n",
    "\t\tself.a_out = Y.reshape(len(Y),1)#actual outputs\n",
    "\t\tself.p_outputs = np.zeros(Y.shape) #holds predicted outputs\n",
    "\n",
    "\t\tprint(self.hidden_weights, self.hidden_bias)\n",
    "\n",
    "\t\tprint(self.output_weights, self.ouput_bias)\n",
    "\n",
    "\n",
    "\tdef load_model(self,model):\n",
    "\n",
    "\t\tself.hidden_weights = model['hidden_weights']\n",
    "\t\tself.hidden_bias = model['hidden_bias']\n",
    "\n",
    "\t\tself.output_weights = model['output_weights']\n",
    "\t\tself.ouput_bias = model['ouput_bias']\n",
    "\t\t\n",
    "\t\tprint(\"MODEL LOADED SUCCESSFULLY\")\n",
    "\n",
    "\n",
    "\n",
    "\tdef save_model(self):\n",
    "\n",
    "\t\tmodel = {\n",
    "\t\t\t\"hidden_weights\":self.hidden_weights,\n",
    "\t\t\t\"hidden_bias\": self.hidden_bias,\n",
    "\t\t\t\"output_weights\": self.output_weights,\n",
    "\t\t\t\"ouput_bias\":self.ouput_bias,\n",
    "\t\t}\n",
    "\n",
    "\t\t#save model as npy file\n",
    "\t\tnp.save('model.npy',model)\n",
    "\t\tprint(\"MODEL SAVED SUCCESSFULLY AS model.npy\")\n",
    "\n",
    "\n",
    "\n",
    "\tdef predict(self,X):\n",
    "\t\t#predict using a different input\n",
    "\t\tself.inputs = X\n",
    "\t\treturn normalize(self.forward_pass())\n",
    "\n",
    "\tdef forward_pass(self):\n",
    "\t\tself.hidden_nodes = sigmoid(np.add(np.dot(self.inputs, self.hidden_weights),self.hidden_bias)) #contains hidden node inputs\n",
    "\t\toutputs = sigmoid(np.add(np.dot(self.hidden_nodes, self.output_weights),self.ouput_bias)) #contain output prediction\n",
    "\t\treturn outputs\n",
    "\n",
    "\tdef back_propagration(self,l_rate):\n",
    "\t\t#output error and delta\n",
    "\t\tself.output_error = self.a_out - self.p_outputs\n",
    "\t\tself.output_delta = self.output_error * n_derivatives(self.p_outputs)\n",
    "\n",
    "\t\t#hidden error and delta\n",
    "\t\tself.hidden_error = np.dot(self.output_delta,self.output_weights.T)\n",
    "\t\tself.hidden_delta = self.hidden_error*n_derivatives(self.hidden_nodes)\n",
    "\n",
    "\t\t#update weights\n",
    "\t\tself.output_weights += np.dot(self.hidden_nodes.T,self.output_delta) * l_rate\n",
    "\t\tself.hidden_weights += np.dot(self.inputs.T,self.hidden_delta) * l_rate\n",
    "\n",
    "\t\t# #update biases\n",
    "\t\tself.hidden_bias  += np.sum(self.hidden_delta,axis=0) * l_rate\n",
    "\t\tself.ouput_bias += np.sum(self.output_delta,axis=0)  *l_rate\n",
    "\t\treturn\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tself.p_outputs = self.forward_pass()\n",
    "\t\tself.back_propagration(0.00001) #use learning rate\n",
    "\t\treturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab598c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20560 entries, 140 to 9752\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           20560 non-null  object \n",
      " 1   Temperature    20560 non-null  float64\n",
      " 2   Humidity       20560 non-null  float64\n",
      " 3   Light          20560 non-null  float64\n",
      " 4   CO2            20560 non-null  float64\n",
      " 5   HumidityRatio  20560 non-null  float64\n",
      " 6   Occupancy      20560 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "number of training set \n",
      " input:  14392 \n",
      " output:  14392\n",
      "number of test set \n",
      " input:  6168 \n",
      " output:  6168\n",
      "MODEL LOADED SUCCESSFULLY\n",
      "[[-0.1665136   0.17153344 -0.24131423 -0.797343  ]\n",
      " [-0.31789128  0.51414195  0.2930291   0.05862465]\n",
      " [-0.17291304 -0.850607   -0.71841289  0.41767282]\n",
      " [-0.84946963  0.16641519  0.14393189  0.70827751]\n",
      " [ 0.78483089  0.33511144  0.30617272  0.92925243]] [0.30897884 0.64564964 0.70028327 0.58746557]\n",
      "[[-0.67378292]\n",
      " [-1.99481591]\n",
      " [-2.77487843]\n",
      " [ 1.10565131]] [0.93543103]\n",
      "Epoch 0 Loss: 0.5\n",
      "Epoch 100 Loss: 0.039379621647738755\n",
      "Epoch 200 Loss: 0.039117831490645315\n",
      "Epoch 300 Loss: 0.03889150915364048\n",
      "Epoch 400 Loss: 0.03869554480908388\n",
      "Epoch 500 Loss: 0.03853511759763781\n",
      "Epoch 600 Loss: 0.038312073127222256\n",
      "Epoch 700 Loss: 0.03818942919282124\n",
      "Epoch 800 Loss: 0.038044570516505095\n",
      "Epoch 900 Loss: 0.038141924082122566\n",
      "Epoch 1000 Loss: 0.037717663870137585\n",
      "Epoch 1100 Loss: 0.03757996148938247\n",
      "Epoch 1200 Loss: 0.037452213243004594\n",
      "Epoch 1300 Loss: 0.03736568980369007\n",
      "Epoch 1400 Loss: 0.03723219461447458\n",
      "MODEL SAVED SUCCESSFULLY AS model.npy\n",
      "EVALUATION TRAIN\n",
      "{'accuracy': 0.961, 'recall': 0.998, 'F1 score': 0.962, 'auc score': 0.961, 'precision': 0.929}\n",
      "EVALUATION TEST1\n",
      "{'accuracy': 0.959, 'recall': 0.998, 'F1 score': 0.898, 'auc score': 0.975, 'precision': 0.815}\n",
      "TRAINING\n",
      "Data points: 21478\n",
      "loss1:0.037123568143798594\n",
      "Confusion Matrix: {'tp': 10719, 'tn': 9919, 'fp': 820, 'fn': 20}\n",
      "Confusion Accuracy: 0.9608902132414564\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Datasets\n",
    "\n",
    "#CLEAN THE DATASET\n",
    "# load data\n",
    "test1 = read_csv('datatest.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "train = read_csv('datatraining.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "test2 = read_csv('datatest2.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "# vertically stack and maintain temporal order\n",
    "data = concat([test1, train, test2])\n",
    "\n",
    "values = data.values\n",
    "#separate inputs and output values\n",
    "INPUT, OUTPUT = values[:, 1:-1], values[:, -1]\n",
    "X, Y = np.array((INPUT),dtype=float), np.array((OUTPUT),dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "# split the dataset\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, shuffle=False, random_state=1)\n",
    "\n",
    "#print dataset information\n",
    "print(data.info())\n",
    "print(\"number of training set \\n input: \", len(trainX),\"\\n output: \",len(trainY))\n",
    "print(\"number of test set \\n input: \", len(testX),\"\\n output: \",len(testY))\n",
    "\n",
    "\n",
    "#get the frequency count of occupied(1) vs not occuppied(0) in the dataset\n",
    "unique, counts = np.unique(trainY, return_counts=True)\n",
    "freq_array = np.asarray((unique, counts),dtype=int).T\n",
    "\n",
    "#upsample the training Data for occuppied(1):\n",
    "up_x = []\n",
    "up_y = []\n",
    "\n",
    "r = (freq_array[0][1]-freq_array[1][1])\n",
    "add = 0\n",
    "cnt=0\n",
    "\n",
    "while add!=r:\n",
    "    if trainY[cnt]==1:\n",
    "        up_x.append(trainX[cnt])\n",
    "        up_y.append(trainY[cnt])\n",
    "        add+=1\n",
    "\n",
    "    cnt+=1\n",
    "    if cnt>=len(trainY) and add<r:\n",
    "        cnt=0\n",
    "\n",
    "\n",
    "up_x = np.array((up_x),dtype=float)\n",
    "up_y = np.array((up_y),dtype=float)\n",
    "\n",
    "trainX = np.concatenate((trainX,up_x),axis=0)\n",
    "trainY = np.concatenate((trainY,up_y),axis=0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Independent Variables:\n",
    "-Temperature, Humidity, Light, CO2, HumidityRatio\n",
    "Dependent Variable: \n",
    "-Occupancy\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#get the frequency count of occupied(1) vs not occuppied(0) in the dataset after upsampling\n",
    "unique, counts = np.unique(trainY, return_counts=True)\n",
    "freq_array = np.asarray((unique, counts),dtype=int).T\n",
    "\n",
    "\n",
    "\n",
    "NN = NeuralNetwork(trainX, trainY,1)\n",
    "\n",
    "for epoch in range(1500):\t\n",
    "    if epoch % 100==0: \n",
    "        print (\"Epoch \" + str(epoch) + \" Loss: \" + str(np.mean(np.square(NN.a_out- NN.p_outputs)))) # mean squared error for loss\n",
    "    NN.train()\n",
    "\n",
    "NN.save_model()\n",
    "\n",
    "print(\"EVALUATION TRAIN\")\n",
    "evaluation(NN.a_out,normalize(NN.p_outputs))\n",
    "print(\"EVALUATION TEST1\")\n",
    "evaluation(testY,NN.predict(testX))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"TRAINING\")\n",
    "print(\"Data points:\",len(trainX))\n",
    "print (\"loss1:\" + str(np.mean(np.square(NN.a_out- NN.p_outputs))))\n",
    "print(\"Confusion Matrix:\",confusion_matrix(NN.p_outputs,NN.a_out))\n",
    "print(\"Confusion Accuracy:\",conf_accuracy(NN.p_outputs,NN.a_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d912c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd16189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
