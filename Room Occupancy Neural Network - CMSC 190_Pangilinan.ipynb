{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736aae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "import random\n",
    "from decimal import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "from sklearn.metrics import f1_score,confusion_matrix,roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68620e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation function and partial derivatives\n",
    "\n",
    "#define sigmoid activation function\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1.0 + np.exp(-x))\n",
    "\n",
    "# neuron derivatives\n",
    "def n_derivatives(z):\n",
    "\treturn z * (1.0 - z)\n",
    "\n",
    "\n",
    "#evaluation functions\n",
    "def evaluation(y_test,y_pred):\n",
    "\n",
    "\tacc = accuracy_score(y_test,y_pred)\n",
    "\trcl = recall_score(y_test,y_pred)\n",
    "\tf1 = f1_score(y_test,y_pred)\n",
    "\tauc_score = roc_auc_score(y_test,y_pred)\n",
    "\tprec_score = precision_score(y_test,y_pred)\n",
    "\n",
    "\tmetric_dict={'accuracy': round(acc,3),\n",
    "\t           'recall': round(rcl,3),\n",
    "\t           'F1 score': round(f1,3),\n",
    "\t           'auc score': round(auc_score,3),\n",
    "\t           'precision': round(prec_score,3) \n",
    "\t          }\n",
    "\n",
    "\treturn print(metric_dict)\n",
    "\n",
    "#normalize the prediction \n",
    "def normalize(pred):\n",
    "\tret = np.array((pred))\n",
    "\n",
    "\tfor i in range(len(pred)):\n",
    "\t\tif pred[i]>=0.5: #tp\n",
    "\t\t\tret[i]=1\n",
    "\t\telse:\n",
    "\t\t\tret[i]=0\n",
    "\n",
    "\treturn ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ccb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network Class\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "\t\"\"\"Make a 3-layer network (5-4-1)\"\"\"\n",
    "\tdef __init__(self, X, Y):\n",
    "\t\t#initialized important variables\n",
    "\n",
    "\t\tself.inputs = X\n",
    "\n",
    "\t\tself.hidden_weights = np.random.uniform(low=-0.3, high=0.3, size=(self.inputs.shape[1],5))#weights of hidden layer\n",
    "\t\tself.hidden_bias = np.random.uniform(low=-0.3, high=0.3, size=(5,)) #bias of hidden layer\n",
    "\n",
    "\t\tself.output_weights = np.random.uniform(low=-0.3, high=0.3, size=(5,1)) #weights of output layer\n",
    "\t\tself.ouput_bias = np.random.uniform(low=-0.3, high=0.3, size=(1,))  #bias of the output layer\n",
    "\n",
    "\t\t#------------------------------------------------------------------------------------------------------------#\n",
    "\t\t# self.hidden_weights = np.full((self.inputs.shape[1],3), 0.5, dtype=float) #weights of hidden layer\n",
    "\t\t# self.hidden_bias = np.full((3,), 0.5, dtype=float) #bias of hidden layer\n",
    "\n",
    "\t\t# self.output_weights = np.full((3,1), 0.5, dtype=float) #weights of output layer\n",
    "\t\t# self.ouput_bias = np.full((1,), 0.5, dtype=float) #bias of the output layer\n",
    "\t\t#------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\t\tself.a_out = Y.reshape(len(Y),1)#actual outputs\n",
    "\t\tself.p_outputs = np.zeros(Y.shape) #holds predicted outputs\n",
    "\n",
    "\t\tprint(\"Hidden Nodes Weights: \\n\",self.hidden_weights, \"\\nHidden Nodes Biases: \\n\",self.hidden_bias)\n",
    "        \n",
    "\t\tprint(\"Output Nodes Weights: \\n\",self.output_weights, \"\\nOutput Nodes Biases: \\n\",self.ouput_bias)\n",
    "\n",
    "\tdef predict(self,X):\n",
    "\t\t#predict using a different input\n",
    "\t\tself.inputs = X\n",
    "\t\treturn normalize(self.forward_pass())\n",
    "\n",
    "\tdef forward_pass(self):\n",
    "\t\tself.hidden_nodes = sigmoid(np.add(np.dot(self.inputs, self.hidden_weights),self.hidden_bias)) #contains hidden node inputs\n",
    "\t\toutputs = sigmoid(np.add(np.dot(self.hidden_nodes, self.output_weights),self.ouput_bias)) #contain output prediction\n",
    "\t\treturn outputs\n",
    "\n",
    "\tdef back_propagration(self,l_rate):\n",
    "\t\t#output error and delta\n",
    "\t\tself.output_error = self.a_out - self.p_outputs\n",
    "\t\tself.output_delta = self.output_error * n_derivatives(self.p_outputs)\n",
    "\n",
    "\t\t#hidden error and delta\n",
    "\t\tself.hidden_error = np.dot(self.output_delta,self.output_weights.T)\n",
    "\t\tself.hidden_delta = self.hidden_error*n_derivatives(self.hidden_nodes)\n",
    "\n",
    "\t\t#update weights\n",
    "\t\tself.output_weights += np.dot(self.hidden_nodes.T,self.output_delta) * l_rate\n",
    "\t\tself.hidden_weights += np.dot(self.inputs.T,self.hidden_delta) * l_rate\n",
    "\n",
    "\t\t# #update biases\n",
    "\t\tself.hidden_bias  += np.sum(self.hidden_delta,axis=0) * l_rate\n",
    "\t\tself.ouput_bias += np.sum(self.output_delta,axis=0)  *l_rate\n",
    "\t\treturn\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tself.p_outputs = self.forward_pass()\n",
    "\t\tself.back_propagration(0.00001) #use learning rate\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5573513c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8143 entries, 1 to 8143\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           8143 non-null   object \n",
      " 1   Temperature    8143 non-null   float64\n",
      " 2   Humidity       8143 non-null   float64\n",
      " 3   Light          8143 non-null   float64\n",
      " 4   CO2            8143 non-null   float64\n",
      " 5   HumidityRatio  8143 non-null   float64\n",
      " 6   Occupancy      8143 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 508.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIndependent Variables:\\n-Temperature, Humidity, Light, CO2, HumidityRatio\\nDependent Variable: \\n-Occupancy\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the Datasets\n",
    "\n",
    "#CLEAN THE DATASET\n",
    "# load data\n",
    "test1 = read_csv('datatest.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "train = read_csv('datatraining.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "test2 = read_csv('datatest2.txt', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "values = train.values\n",
    "#separate inputs and output values\n",
    "INPUT, OUTPUT = values[:, 1:-1], values[:, -1]\n",
    "X, Y = np.array((INPUT),dtype=float), np.array((OUTPUT),dtype=float)\n",
    "\n",
    "values1 = test1.values\n",
    "#separate inputs and output values\n",
    "INPUT1, OUTPUT1 = values1[:, 1:-1], values1[:, -1]\n",
    "X1, Y1 = np.array((INPUT1),dtype=float), np.array((OUTPUT1),dtype=float)\n",
    "\n",
    "values2 = test2.values\n",
    "#separate inputs and output values\n",
    "INPUT2, OUTPUT2 = values2[:, 1:-1], values2[:, -1]\n",
    "X2, Y2 = np.array((INPUT2),dtype=float), np.array((OUTPUT2),dtype=float)\n",
    "\n",
    "print(train.info())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Independent Variables:\n",
    "-Temperature, Humidity, Light, CO2, HumidityRatio\n",
    "Dependent Variable: \n",
    "-Occupancy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045347c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Nodes Weights: \n",
      " [[ 0.26403032  0.0279719   0.24525954  0.04229342  0.26454552]\n",
      " [-0.2523892  -0.15168156 -0.03193267  0.0956131  -0.22507156]\n",
      " [ 0.16392271  0.16239853  0.04188457 -0.0964944  -0.16962476]\n",
      " [ 0.03021177  0.20372885 -0.26963074 -0.14679319  0.04604036]\n",
      " [ 0.04615487 -0.1452919   0.08668376 -0.23709165 -0.12107097]] \n",
      "Hidden Nodes Biases: \n",
      " [-0.21258516  0.1446383  -0.12294297 -0.00194525  0.02593869]\n",
      "Output Nodes Weights: \n",
      " [[ 0.29731868]\n",
      " [ 0.25564765]\n",
      " [-0.14874448]\n",
      " [-0.10384646]\n",
      " [ 0.14204808]] \n",
      "Output Nodes Biases: \n",
      " [-0.2470386]\n",
      "Epoch 0 Loss: 0.2123296082524868\n",
      "Epoch 100 Loss: 0.15029764958350336\n",
      "Epoch 200 Loss: 0.1354312221556548\n",
      "Epoch 300 Loss: 0.12645409108131023\n",
      "Epoch 400 Loss: 0.11803048181659069\n",
      "Epoch 500 Loss: 0.11065561442250671\n",
      "Epoch 600 Loss: 0.10661336395742155\n",
      "Epoch 700 Loss: 0.09761154457251636\n",
      "Epoch 800 Loss: 0.09624513539667925\n",
      "Epoch 900 Loss: 0.08790045028368174\n",
      "Epoch 1000 Loss: 0.08382982139290347\n",
      "Epoch 1100 Loss: 0.08401799272755267\n",
      "Epoch 1200 Loss: 0.0788071411391825\n",
      "Epoch 1300 Loss: 0.0764295983011354\n",
      "Epoch 1400 Loss: 0.07557380414919143\n"
     ]
    }
   ],
   "source": [
    "#Create the Neural Network and Train using the training dataset\n",
    "\n",
    "#epoch = 1500 with learning rate of 0.00001\n",
    "\n",
    "NN = NeuralNetwork(X, Y)\n",
    "\n",
    "for epoch in range(1500):\t\n",
    "    if epoch % 100==0: \n",
    "        print (\"Epoch \" + str(epoch) + \" Loss: \" + str(np.mean(np.square(NN.a_out- NN.p_outputs)))) # mean squared error for loss\n",
    "    NN.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb54642c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION TRAIN\n",
      "{'accuracy': 0.938, 'recall': 0.988, 'F1 score': 0.872, 'auc score': 0.957, 'precision': 0.78}\n",
      "EVALUATION TEST1\n",
      "{'accuracy': 0.971, 'recall': 1.0, 'F1 score': 0.962, 'auc score': 0.977, 'precision': 0.927}\n",
      "EVALUATION TEST2\n",
      "{'accuracy': 0.939, 'recall': 0.999, 'F1 score': 0.873, 'auc score': 0.961, 'precision': 0.775}\n"
     ]
    }
   ],
   "source": [
    "#evaluate the Neural Network\n",
    "print(\"EVALUATION TRAIN\")\n",
    "evaluation(NN.a_out,normalize(NN.p_outputs))\n",
    "print(\"EVALUATION TEST1\")\n",
    "evaluation(Y1,NN.predict(X1))\n",
    "print(\"EVALUATION TEST2\")\n",
    "evaluation(Y2,NN.predict(X2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95ad76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bcd43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
